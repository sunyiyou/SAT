# Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations

This is the source code for [Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations](https://arxiv.org/abs/xxx)
by Yiyou Sun, Yu Gai, Lijie Chen, Abhilasha Ravichander, Yejin Choi and Dawn Song.

## Benchmark Results Reproduction

### Requirements

The running environment file is in `./requirements.txt'

### Data source: [HALoGEN](https://halogen-hallucinations.github.io/)  

The preprocessed subset of prompts and corresponding hallucination subsequences in the output are stored in `./halu_results`. The preprossing code is `./1_data_prepare.py`

### Evaluation

Add your openai key to `./key.py`


## Demo 



## Citation


If you use our codebase, please cite our work:

```
@article{sun2025sat,
  title={Why and How LLMs Hallucinate: Connecting the Dots with Subsequence Associations},
  author={Sun, Yiyou and Gai, Yu and Chen, Lijie and Ravichander, Abhilasha and Choi, Yejin and Song, Dawn},
  journal={arxiv},
  year={2025}
}
```

